{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization , GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuDNN Version: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"CuDNN Version:\", tf.test.is_built_with_cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ChCuDNN is not available.eck if CuDNN is available\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"CuDNN is available.\")\n",
    "else:\n",
    "    print(\"CuDNN is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_csv_url = r\"C:/Users/gusta/Documents/Data Science Bootcamp/Data Science/Final Project/Data/completeAudioSetdf.csv\"\n",
    "\n",
    "data_path = pd.read_csv(github_csv_url)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOISE\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# STRETCH\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "# SHIFT\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "# PITCH\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=int(pitch_factor * 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data, sr, frame_length=2048, hop_length=512, flatten=True):\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result\n",
    "\n",
    "def get_features(path,duration=2.5, offset=0.6):\n",
    "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
    "    aud=extract_features(data)\n",
    "    audio=np.array(aud)\n",
    "    \n",
    "    noised_audio=noise(data)\n",
    "    aud2=extract_features(noised_audio)\n",
    "    audio=np.vstack((audio,aud2))\n",
    "    \n",
    "    pitched_audio=pitch(data,sr)\n",
    "    aud3=extract_features(pitched_audio)\n",
    "    audio=np.vstack((audio,aud3))\n",
    "    \n",
    "    pitched_audio1=pitch(data,sr)\n",
    "    pitched_noised_audio=noise(pitched_audio1)\n",
    "    aud4=extract_features(pitched_noised_audio)\n",
    "    audio=np.vstack((audio,aud4))\n",
    "    \n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "# Define a function to get features for a single audio file\n",
    "def process_feature(path, emotion):\n",
    "    features = get_features(path)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for ele in features:\n",
    "        X.append(ele)\n",
    "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
    "        Y.append(emotion)\n",
    "    return X, Y\n",
    "\n",
    "paths = data_path.Path\n",
    "emotions = data_path.Emotions\n",
    "\n",
    "# Run the loop in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(process_feature)(path, emotion) for (path, emotion) in zip(paths, emotions))\n",
    "\n",
    "# Collect the results\n",
    "X = []\n",
    "Y = []\n",
    "for result in results:\n",
    "    x, y = result\n",
    "    X.extend(x)\n",
    "    Y.extend(y)\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions = pd.DataFrame(X)\n",
    "Emotions['Emotions'] = Y\n",
    "Emotions.to_csv('emotion.csv', index=False)\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Emotions.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions=Emotions.fillna(0)\n",
    "print(Emotions.isna().any())\n",
    "Emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Emotions.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesing the Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking all rows and all cols without last col for X which include features\n",
    "#taking last col for Y, which include the emotions\n",
    "\n",
    "\n",
    "X = Emotions.iloc[: ,:-1].values\n",
    "Y = Emotions['Emotions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42,test_size=0.2, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape for lstm\n",
    "X_train = x_train.reshape(x_train.shape[0] , x_train.shape[1] , 1)\n",
    "X_test = x_test.reshape(x_test.shape[0] , x_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling our data with sklearn's Standard scaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "model_checkpoint = ModelCheckpoint('best_model1_weights.h5', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor='val_acc',mode='auto',patience=5,restore_best_weights=True)\n",
    "lr_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape for CNN_LSTM MODEL\n",
    "\n",
    "x_traincnn =np.expand_dims(x_train, axis=2)\n",
    "x_testcnn= np.expand_dims(x_test, axis=2)\n",
    "x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape\n",
    "#x_testcnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "\n",
    "model = keras.Sequential([\n",
    "    L.Conv1D(512,kernel_size=5, strides=1,padding='same', activation='relu',input_shape=(X_train.shape[1],1)),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    \n",
    "    L.Conv1D(512,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the second max pooling layer\n",
    "    \n",
    "    L.Conv1D(256,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    \n",
    "    L.Conv1D(256,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the fourth max pooling layer\n",
    "    \n",
    "    L.Conv1D(128,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=3,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the fifth max pooling layer\n",
    "    \n",
    "    L.Flatten(),\n",
    "    L.Dense(512,activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.Dense(8,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_traincnn, y_train, epochs=50, validation_data=(x_testcnn, y_test), batch_size=64,callbacks=[early_stop,lr_reduction,model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To save history callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'C:/Users/gusta/VolafoneSER/Data/history_callback.pl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_path, 'wb') as file:\n",
    "#     pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_path, 'rb') as file:\n",
    "#     loaded_history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(x_testcnn,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(50)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test data.\n",
    "pred_test0 = model.predict(x_testcnn)\n",
    "y_pred0 = encoder.inverse_transform(pred_test0)\n",
    "y_test0 = encoder.inverse_transform(y_test)\n",
    "\n",
    "# Check for random predictions\n",
    "df0 = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df0['Predicted Labels'] = y_pred0.flatten()\n",
    "df0['Actual Labels'] = y_test0.flatten()\n",
    "\n",
    "df0.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test0, y_pred0)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()\n",
    "print(classification_report(y_test0, y_pred0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"CNN_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"CNN_model_weights.h5\")\n",
    "print(\"Saved model to disk\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "json_file = open('/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/kaggle/working/best_model1_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn,y_test)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading our Stnadrad Scaler and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving scaler\n",
    "with open('scaler2.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Loading scaler\n",
    "with open('scaler2.pickle', 'rb') as f:\n",
    "    scaler2 = pickle.load(f)\n",
    "\n",
    "# Saving encoder\n",
    "with open('encoder2.pickle', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# Loading encoder\n",
    "with open('encoder2.pickle', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "\n",
    "    \n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "json_file = open('/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/kaggle/working/best_model1_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/kaggle/working/scaler2.pickle', 'rb') as f:\n",
    "    scaler2 = pickle.load(f)\n",
    "    \n",
    "with open('/kaggle/working/encoder2.pickle', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "\n",
    "    \n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_feat(path):\n",
    "    d, s_rate= librosa.load(path, duration=2.5, offset=0.6)\n",
    "    res=extract_features(d)\n",
    "    result=np.array(res)\n",
    "    result=np.reshape(result,newshape=(1,2376))\n",
    "    i_result = scaler2.transform(result)\n",
    "    final_result=np.expand_dims(i_result, axis=2)\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=get_predict_feat(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav\")\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions1={1:'Neutral', 2:'Calm', 3:'Happy', 4:'Sad', 5:'Angry', 6:'Fear', 7:'Disgust',8:'Surprise'}\n",
    "def prediction(path1):\n",
    "    res=get_predict_feat(path1)\n",
    "    predictions=loaded_model.predict(res)\n",
    "    y_pred = encoder2.inverse_transform(predictions)\n",
    "    print(y_pred[0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-01-01-01-01-02.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-01-01-01-01-01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-05-01-02-02-01.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
